# SwiftSolve â€“ Comprehensive Technical Specification (v1.0.0)

> **Read this once â€“ build correctly forever.**  Any deviation without an approved changeâ€‘request (CR) will be rejected at review.
>
> Latest update: 2025â€‘07â€‘24  â–ª  SchemaÂ version: 1.0.0  â–ª  Maintainer: VEAB

---

## 1Â Â Project Context Â ğŸ“°

### 1.1Â Â Problem Statement

Large Language Models (LLMs) can already pass â‰¥â€¯90â€¯% of unit tests on many coding benchmarks, yet they frequently blow past strict runtime (TLE) and memory (MLE) limits in competitiveâ€‘programming and latencyâ€‘sensitive production systems.  SwiftSolve closes that gap by **coâ€‘optimising correctness and Bigâ€‘O efficiency** through a modular, agentic pipeline.

### 1.2Â Â Highâ€‘Level Storyboard

1. A user (human or orchestrator) POSTs a naturalâ€‘language problem description to `/solve` or feeds a JSON task to the CLI runner.
2. The **Planner** (ClaudeÂ 4Â Opus) converts prose into a structured algorithmic sketch.
3. A **StaticÂ Pruner** shields the system from obviously inefficient plans (e.g. `O(nÂ²)` sortâ€‘inâ€‘loop patterns).
4. The **Coder** (GPTâ€‘4.1) turns the approved plan into ISOÂ C++â€¯17 source.
5. The **Profiler** compiles and executes the code inside a deterministic Docker sandbox, capturing wallâ€‘time + RSS across logarithmic input scales.
6. The **ComplexityÂ Analyst** analyses the telemetry, fits empirical complexity, checks constraints, and either: \*Â declares success, or \*Â routes a JSON patch to the Coder (local fix) or the Planner (algorithmic overhaul).
7. All artefacts are persisted as JSON under `logs/<task_id>/iter_<i>/` for full replay.

### 1.3Â Â Design Principles

| Principle           | Rationale                                                  |
| ------------------- | ---------------------------------------------------------- |
| **Modularity**      | Swap Planner/Coder models independently                    |
| **Determinism**     | Seed control + cached prompts + Docker sandbox             |
| **Cost Awareness**  | Static pruning + early termination to minimise token spend |
| **Reproducibility** | Every artefact logged with schemaÂ version & UTC timestamp  |
| **Security**        | Untrusted C++ runs inside cgroupâ€‘limited container         |

### 1.4Â Â Agent Contract Summary

| Agent    | ModelÂ /Â Tool        | Function                           | In â†’ Out                           |
| -------- | ------------------- | ---------------------------------- | ---------------------------------- |
| Planner  | ClaudeÂ 4Â Opus       | Algorithm strategy synthesis       | `ProblemInput` â†’ `PlanMessage`     |
| Sâ€‘Pruner | regexÂ +Â AST         | Heuristic plan rejection           | `PlanMessage` â†’ bool               |
| Coder    | GPTâ€‘4.1              | C++â€¯17 code generation             | `PlanMessage` â†’ `CodeMessage`      |
| Profiler | g++ + /usr/bin/time | Empirical runtime & memory capture | `CodeMessage` â†’ `ProfileReport`    |
| Analyst  | GPTâ€‘4.1Â +Â heuristic  | Complexity fit & routing decision  | `ProfileReport` â†’ `VerdictMessage` |

### 1.5Â Â Endâ€‘toâ€‘End Control Flow (verbose)

1. **Validation** â€“ Incoming JSON must satisfy `ProblemInput` schema; otherwise FastAPI 422.
2. **Plan Generation** â€“ Planner prompt contains: problem text, required JSON keys, max tokens 512.  Response must parse under `PlanMessage.model_validate()`.
3. **Static Prune** â€“ If `validate(plan)==False`  â†’Â return `RunResult(status=STATIC_PRUNE_FAILED)`.
4. **Iterative Loop** (`iterÂ =Â 0..max_iterâˆ’1`)
   1. Call **Coder**; response parsed into `CodeMessage`.  Failure? retryÂ once â†’ else `RunResult(status=FAILED)`.
   2. **Profiler** compiles with `g++ -O2 -std=c++17`.  Resource caps: wallÂ =Â `runtime_limit+250`Â ms, RSSÂ â‰¤â€¯512Â MB, stackÂ 256Â MB.  Parse `/usr/bin/timeÂ -v`.
   3. **Analyst** receives `ProfileReport`, fits logâ€‘log slope, classifies complexity & memory class; returns `VerdictMessage`.
   4. Check `verdict.efficient`.  If true â†’ success.  Else route:
      - `target_agent==CODER` â†’ patch prompt; Coder reruns.
      - else â†’ Planner revise prompt; go to 4.1.
   5. Stop if `perf_gainÂ <Â diminish_delta` or `iter==max_iterâˆ’1` or â‰¥â€¯2 agent crashes.
5. Assemble `RunResult`, write to `logs_uri`, return via API.

### 1.6Â Â JSONÂ Communication Spec (excerpt)

```jsonc
// PlanMessage (envelope + payload)
{
  "type": "plan",
  "task_id": "CF1285C",
  "iteration": 0,
  "timestamp_utc": "2025â€‘07â€‘24T20:41:11Z",
  "schema_version": "1.0.0",
  "algorithm": "twoâ€‘pointer sliding window",
  "input_bounds": {"n": 100000},
  "constraints": {"runtime_limit": 2000, "memory_limit": 512}
}
```

*All six message types (**`PlanMessage`**, **`CodeMessage`**, **`ProfileReport`**, **`VerdictMessage`**, **`ProblemInput`**, **`RunResult`**) are fully defined in **`schemas/__init__.py`** and ****must not**** be duplicated elsewhere.*

### 1.7Â Â Static Pruner Rulebook

- **Loop depth**Â >â€¯2 & `n â‰¥ 1e5`  â†’ reject.
- **Sortâ€‘inâ€‘loop** & `n â‰¥ 1e3`      â†’ reject.
- **Unbounded recursion** & `n â‰¥ 1e4` â†’ reject.
- Configurable via `static_pruner/pruner.toml` hotâ€‘reload.

### 1.8Â Â Sandbox Constraints

- Namespace: nonâ€‘root, seccomp `docker/default` + no net.
- `resource.setrlimit`:
  - `RLIMIT_AS`Â =Â 512â€¯MB
  - `RLIMIT_STACK`Â =Â 256â€¯MB
  - `RLIMIT_FSIZE`Â =Â 50â€¯MB (stdout/stderr cap)
- Crash codes propagated to controller as `RunStatus.SANDBOX_ERROR`.

### 1.9Â Â Evaluation Metrics

| Metric          | Definition                                       |
| --------------- | ------------------------------------------------ |
| pass\@k         | â‰¥â€¯1 of topâ€‘k programs passes official unit tests |
| eff\@k\_runtime | â‰¥â€¯1 of topâ€‘k passes time limit                   |
| eff\@k\_memory  | â‰¥â€¯1 of topâ€‘k stays <â€¯memory limit                |
| TLE/MLE rate    | % of executions exceeding runtime or memory cap  |
| Iteration count | Mean #loops until `efficient==true`              |

### 1.10Â Â Datasets

- **BigO(Bench)** â€“ 50 tasks across O(1)â€“O(nÂ²).
- **Codeforces Divâ€‘2** â€“ 25 tasks (800â€“1800 rating).
- Stored under `datasets/<source>/task_<id>.json` following `task_format.py`.

### 1.11Â Â Security & Privacy

No user code is stored beyond telemetry; LLM prompts are cached encrypted at rest (AESâ€‘GCM) if `CACHE_ENCRYPT_KEY` is set.

### 1.12Â Â OpenAPI Exposure

- `/solve` â€“ POST â€“ body `ProblemInput`, response `RunResult`.
- `/healthz` â€“ GET â€“ returns 200 + git hash + schema version.

---

## 2Â Â Tech Stack Â ğŸ› ï¸

### 2.1Â Â Languages & Runtimes

- PythonÂ 3.11.13 (orchestrator)
- C++â€¯17 (generated code)
- Bash + GNU coreutils (sandbox scripts)

### 2.2Â Â Key Libraries

| Domain   | Package                           | Version         | Notes                    |
| -------- | --------------------------------- | --------------- | ------------------------ |
| API      | FastAPI, Uvicorn[standard]        | 0.116.1         | ASGI + Hot reload        |
| LLM SDKs | openai, anthropic                 | 1.95.1Â Â·Â 0.57.1 | Model calls              |
| Schema   | PydanticÂ v2.x + pydanticâ€‘settings | 2.9.2           | Validation + env config  |
| Testing  | pytest, pytestâ€‘asyncio            | 8.1.0Â Â·Â 0.23.5  | Unit & async tests       |
| Lint     | Ruff, Mypy, Preâ€‘commit            | latest          | CI static analysis       |
| Logging  | Rich, loguru (optional)           | 13.7.1          | Colour logs + tracebacks |
| Data     | pandas, plotnine, orjson          | pinned          | Evaluation & plotting    |

### 2.3Â Â Infrastructure

- DockerÂ 24.x  âœ UbuntuÂ 20.04 base image.
- TerraformÂ 1.8.x  âœ GKE Autopilot cluster.
- GitHub Actions CI  âœ 3.11/3.12 matrix, push & PR.

### 2.4Â Â EnvironmentÂ Variables

| Variable            | Purpose                                |
| ------------------- | -------------------------------------- |
| `OPENAI_API_KEY`    | GPTâ€‘4.1 access                          |
| `ANTHROPIC_API_KEY` | ClaudeÂ 4Â Opus access                   |
| `LOG_LEVEL`         | Default `INFO`, override to `DEBUG`    |
| `CACHE_ENCRYPT_KEY` | 32â€‘byte key for encrypted prompt cache |

### 2.5Â Â VersionÂ Pinning Rules

- Semantic pin (`==`) for prod deps in `requirements.txt`.
- Devâ€‘only tools (`ruff`, `mypy`) in `requirements-dev.txt`.
- `pyproject.toml` sets `requires-python == 3.11.13`.

---

## 3Â Â Repository Layout & File Descriptions Â ğŸ“

```text
src/swiftsolve/
â”œâ”€â”€ main.py               # FastAPI + CLI entry
â”œâ”€â”€ api/routes.py         # /solve, /healthz
â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ solve_loop.py     # Core orchestration
â”‚   â””â”€â”€ router.py         # FastAPI wrapper (planned)
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base.py           # Agent ABC + retry/caching hooks
â”‚   â”œâ”€â”€ planner.py        # Claude client, prompt templates
â”‚   â”œâ”€â”€ coder.py          # GPTâ€‘4.1 client, codeâ€‘json extraction
â”‚   â”œâ”€â”€ profiler.py       # Sandbox wrapper + telemetry parse
â”‚   â””â”€â”€ analyst.py        # Complexity fit + patch routing
â”œâ”€â”€ static_pruner/pruner.py # Regex + AST heuristics
â”œâ”€â”€ sandbox/
â”‚   â”œâ”€â”€ run_in_sandbox.py   # g++ compile & exec with limits
â”‚   â””â”€â”€ docker_utils.py     # image build & push (WIP)
â”œâ”€â”€ schemas/__init__.py     # Unified Pydantic v2 models
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ parse_bigobench.py  # HTML/JSON â†’ task format
â”‚   â”œâ”€â”€ parse_codeforces.py # Scrape + IO normalisation
â”‚   â””â”€â”€ task_format.py      # Shared spec & validation
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py          # pass@k, eff@k_* calculators
â”‚   â””â”€â”€ stats.py            # DataFrame aggregation & plots
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py           # pydanticâ€‘settings Settings()
â”‚   â””â”€â”€ logger.py           # Colour + rotating logs
â””â”€â”€ tests/
    â”œâ”€â”€ test_agents.py      # Planner/Coder mocks
    â”œâ”€â”€ test_pruner.py      # Heuristic edge cases
    â”œâ”€â”€ test_schema.py      # JSON roundâ€‘trip & forbid extras
    â””â”€â”€ test_sandbox.py     # Compile & run smoke test
```

Every file **must** include docstring headers explaining purpose, inputs, and sideâ€‘effects.

---

## 4Â Â Task Megaâ€‘Spec Â ğŸ“‹

The following hierarchy represents **all work items** required for SwiftSolveÂ v1.0.  Completed items are prefixed âœ”.

### 4.1Â Â PhaseÂ A â€“ Foundations

- **A1Â Environment Setup**
  - A1.1Â Create pyenvÂ 3.11.13 and poetry project.
  - A1.2Â Add `requirements.txt` & `requirements-dev.txt`.
  - A1.3Â Configure preâ€‘commit (ruff, black, mypy, isort).
- **A2Â Schema Layer**
  - A2.1Â Design envelope & message enums.
  - âœ”Â A2.2Â Implement `schemas/__init__.py` with Pydantic v2.
  - A2.3Â Add `test_schema.py` (field presence, forbid extras).
- **A3Â Logging & Config**
  - âœ”Â A3.1Â `utils.logger` colour + rotating handler.
  - âœ”Â A3.2Â `utils.config` Settings singleton via pydanticâ€‘settings.

### 4.2Â Â PhaseÂ B â€“ Core Loop (MVP)

- **B1Â Planner Agent**
  - B1.1Â Prompt template design (JSONâ€‘only output).
  - B1.2Â Claude client wrapper with retry & cache (SqliteÂ +Â orjson).
  - B1.3Â Unit tests: valid JSON, fallback plan.
- **B2Â StaticÂ Pruner**
  - âœ”Â B2.1Â Regex + AST rule implementation.
  - B2.2Â `pruner.toml` external rule config.
  - B2.3Â Benchmark falseâ€‘positive rate on 100 plans.
- **B3Â Coder Agent**
  - B3.1Â JSONâ€‘only code prompt; ensure includes & I/O.
  - B3.2Â Escapeâ€‘sequence cleaning; compile smoke test.
  - B3.3Â Inject optional chrono & memory hooks on `debug` flag.
- **B4Â Solve Loop v0**
  - B4.1Â Integrate Planner â†’ Pruner â†’ Coder chain.
  - B4.2Â FastAPI `/solve` returns stub `RunResult`.

### 4.3Â Â PhaseÂ C â€“ Profiler & Analyst

- **C1Â Sandbox Runtime**
  - C1.1Â Dockerfile (UbuntuÂ 20.04, g++â€‘10, time, gprof).
  - C1.2Â `run_in_sandbox.py` compileâ†’runâ†’timeâ†’RSS.
  - C1.3Â `resource.setrlimit` caps; stackÂ 256Â MB.
- **C2Â Profiler Agent**
  - C2.1Â Generate logarithmic input scales.
  - C2.2Â Parse `/usr/bin/time -v` (regex).
  - C2.3Â Produce `ProfileReport`.
- **C3Â Complexity Analyst**
  - C3.1Â Heuristic slope fit (logâ€‘log).
  - C3.2Â GPTâ€‘4.1 fallback for ambiguous curves.
  - C3.3Â Patch routing logic (`TargetAgent`).
- **C4Â Termination Logic**
  - C4.1Â Implement `perf_gain` check vs `diminish_delta`.
  - C4.2Â Loop abort on 2 agent failures.

### 4.4Â Â PhaseÂ D â€“ Dataset & Metrics

- **D1Â Dataset Parsers**
  - D1.1Â HTML scrape BigO(Bench) tasks.
  - D1.2Â REST scrape Codeforces tasks.
  - D1.3Â Validate against `task_format.py`.
- **D2Â Batch Runner**
  - D2.1Â CLI flags: `--benchmark`, `--seeds`, `--replans`.
  - D2.2Â Multiprocess pool, progress bar (tqdm).
  - D2.3Â Store artefacts under `results/<task>/seed_<s>/`.
- **D3Â Metrics & Plots**
  - D3.1Â Calc pass\@k, eff\@k\_\*, TLE/MLE.
  - D3.2Â Plot runtime curves (plotnine) per class.
  - D3.3Â Generate Markdown + CSV summary.

### 4.5Â Â PhaseÂ E â€“ Deployment & Publication

- **E1Â Infrastructure as Code**
  - E1.1Â Terraform modules for GKE Autopilot.
  - E1.2Â GCS bucket + Cloud NAT egress.
- **E2Â Scaling Run**
  - E2.1Â RunÂ 12â€¯000 cycles; monitor cost.
  - E2.2Â Download results + run evaluation.
- **E3Â Paper & Artefact**
  - E3.1Â Write methodology, experiments, ablations.
  - E3.2Â Insert tables: eff\@1, iteration counts.
  - E3.3Â Prepare artefact for NeurIPS reproducibility checklist.

---

Note that for testing, we will be using gpt-4.1-mini and claude-sonnet-4 for budgeting reasons.